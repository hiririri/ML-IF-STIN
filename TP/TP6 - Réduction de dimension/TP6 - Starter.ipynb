{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP7 - Réduction de dimensions\n",
    "\n",
    "Peut-on déduire le genre d'un film à son poster ? Nous nous proposons d'explorer cela en exploitant la réduction de dimension. On s'appuie sur le dataset publié sur [Kaggle](https://www.kaggle.com/datasets/raman77768/movie-classifier) lui-même extrait de ce [dataset](https://www.cs.ccu.edu.tw/~wtchu/projects/MoviePoster/index.html) construit pour répondre à la problématique que nous nous sommes posé, initialement avec des réseaux de neurones.\n",
    "\n",
    "Commençons par construire un dataset exploitable pour nous. Nous allons devoir :\n",
    "1. Charger l'image et son identifiant\n",
    "2. Modifier l'image de sorte qu'elle soit de taille uniforme\n",
    "3. Applatir l'image pour former le dataset tabulaire final\n",
    "\n",
    "L'identifiant nous servira plus tard. Nous choisissons ici la taille standard (50, 50, 3) puisque les images sont en couleurs, cela nous amènera à un dataset de taille $75\\times75\\times3=7500$. Commençons par construire une fonction qui nous permettra de charger les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "path = \"Multi_Label_dataset/Images\"\n",
    "\n",
    "\n",
    "def get_image(id, path=path):\n",
    "    image_path = path + \"/\" + id + \".jpg\"\n",
    "    image = Image.open(image_path)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons maintenant le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset = []\n",
    "images = os.listdir(path)\n",
    "for file in images:\n",
    "    image_path = path + \"/\" + file\n",
    "    image = Image.open(image_path).resize((50, 50))\n",
    "    dataset.append(np.array(image).flatten())\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "df[\"Id\"] = [image.replace(\".jpg\", \"\") for image in images]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler avec l'algorithme UMAP, qui s'appuie sur une descente de gradient. Pour simplifier cette étape, nous proposons de préparer la matrice en conséquence.\n",
    "\n",
    "**Consigne** : Après avoir créer une matrice *X* qui correspond à *df* sans la colonne *Id*, standardiser les données à l'aide de la classe [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Calculer les coordonnées dans la nouvelle base de chaque observations avec l'algorithme [UMAP](https://umap-learn.readthedocs.io/en/latest/). On précisera que l'on souhaite obtenir uniquement deux dimensions finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif a présent est d'exploiter la nouvelle base de deux manières :\n",
    "1. **Visualiser** l'ensemble des affiches sur un même graphique, et leur répartition selon les genre\n",
    "2. **Identifier** les affiches les plus proches selon la nouvelle base\n",
    "\n",
    "\n",
    "## Objectif 1: Visualiser\n",
    "Pour réussir le premier objectif, exploitons le dataset qui spécifie les genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = pd.read_csv(\"Multi_Label_dataset/train.csv\")\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons à nouveau la colonne *Id* présente pour pouvoir faire la jointure. Notons que nous n'avons pas un unique genre pour chaque films. Ajoutons à notre *embedding* les informations de cette base de données.\n",
    "\n",
    "**Consigne** : Définir une fonction `augment_embedding` qui prend en paramètre un *embedding* *X*. Elle ajoutera à cet embedding les identifiants issus du dataset *df* pour ensuite faire la jointure avec le dataset *df_categories*. On utilisera la méthode [`merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) pour la jointure, et la méthode [`dropna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) pour supprimer les affiches dont on ne connait pas le genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant la capacité de visualiser l'embedding et d'y projeter un genre.\n",
    "\n",
    "**Consigne** : Définir la fonction `plot_embedding_genre` qui prend en paramètre :\n",
    "* *embedding*: un dataframe qui correspond à l'embedding apprit\n",
    "* *genre*: chaîne de caractère qui correspond à une des colonnes de genre\n",
    "* *title*: chaîne de caractère valant *None* par défaut, et qui permet de personnaliser le titre, sinon n'en affiche pas\n",
    "La fonction affichera le scatter plot de chacune des affiches selon l'embedding apprit, et afficher de deux couleurs différentes les observations associées au genre d'intérêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Appliquer la fonction `plot_embedding_genre` sur plusieurs genre pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'ici nous avons travailler avec les valeurs par défaut de l'algorithme UMAP, et donc visualiser qu'un unique embedding possible.\n",
    "\n",
    "**Consigne** : Définir la fonction `learn_embedding` qui prend en paramètre les paramètres à transmettre à l'algorithme UMAP. Elle renverra un embedding apprit avec les paramètres renseigné pour UMAP, et il sera augmenté avec la fonction `augment_embedding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Visualiser, pour un même genre, différent paramètre de UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif 2: Identifier\n",
    "\n",
    "On souhaite à présent identifier pour une affiche donnée les affiches les plus proches. Pour définir *l'affiche la plus proche* on décide de travailler avec un embedding apprit, et deux possibilités de distance.\n",
    "* **Distance euclidienne** : la distance classique, celle qui correspond au monde physique. Pour deux vecteurs $u, v \\in \\mathbb{R}^n$, la distance euclidienne $d$ est :\n",
    "$$d(u, v) = \\sqrt{\\sum_{i=1}^n (u_i - v_i)^2}$$\n",
    "* **Distance cosinus** : mesure de similarité entre deux vecteurs se basant sur l'angle entre les deux vecteurs. Pour deux vecteurs $u, v \\in \\mathbb{R}^n$, la distance cosinus $d$ est :\n",
    "$$d(u, v) = 1 - \\frac{\\langle u, v\\rangle}{\\|u\\|\\|v\\|}$$\n",
    "\n",
    "**Consigne** : Définir les fonctions suivante, qui prendront en paramètres un embedding de dimension 2 et une observation:\n",
    "1. `euclidean_distance`: renvoie la distance euclidienne entre l'observation et l'ensemble de l'embedding\n",
    "2. `cosinus_distance`: renvoie la distance cosinus entre l'observation et l'ensemble de l'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Définir la fonction `view_neighbors` qui prendra en paramètre \n",
    "* *embedding*: une matrice qui correspond à l'embedding d'intérêt\n",
    "* *row_index*: un entier qui correspond à l'indice de l'affiche d'intérêt\n",
    "* *n_neighbors*: le nombre de voisin que l'on souhaite visualiser, par défaut 2\n",
    "* *distance*: fonction qui correspond à la distance que l'on souhaite utiliser\n",
    "* *figsize*: un tuple qui permet de contrôler la taille du graphique généré\n",
    "\n",
    "Elle renverra l'affiche initiale et les *n_neighbors* associés selon la distance choisie pour l'embedding précisé. On pourra utiliser la méthode [`nsmallest`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html) et la fonction `get_image` pour afficher les images dans leurs format initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Exploiter la fonction `view_neighbors` et juger de la qualité de l'embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
