{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - Arbre et Random Forest : Prédiction du churn\n",
    "\n",
    "Issue d'un [dataset](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset) disponible sur Kaggle.\n",
    "\n",
    "Le dataset pour cette séance correspond à des clients qui ont quitté ou non une banque. On souhaite savoir si le client va quitter la banque. Nous allons utiliser des arbres de décisions et des random forest pour répondre à ce problème.\n",
    "\n",
    "## Contrôle de la qualité de donnée\n",
    "\n",
    "Commençons par importer les données et les observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>products_number</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15574012</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15592531</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15656148</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15792365</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15592389</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  credit_score  country  gender  age  tenure    balance  \\\n",
       "0     15634602           619   France  Female   42       2       0.00   \n",
       "1     15647311           608    Spain  Female   41       1   83807.86   \n",
       "2     15619304           502   France  Female   42       8  159660.80   \n",
       "3     15701354           699   France  Female   39       1       0.00   \n",
       "4     15737888           850    Spain  Female   43       2  125510.82   \n",
       "5     15574012           645    Spain    Male   44       8  113755.78   \n",
       "6     15592531           822   France    Male   50       7       0.00   \n",
       "7     15656148           376  Germany  Female   29       4  115046.74   \n",
       "8     15792365           501   France    Male   44       4  142051.07   \n",
       "9     15592389           684   France    Male   27       2  134603.88   \n",
       "\n",
       "   products_number  credit_card  active_member  estimated_salary  churn  \n",
       "0                1            1              1         101348.88      1  \n",
       "1                1            0              1         112542.58      0  \n",
       "2                3            1              0         113931.57      1  \n",
       "3                2            0              0          93826.63      0  \n",
       "4                1            1              1          79084.10      0  \n",
       "5                2            1              0         149756.71      1  \n",
       "6                2            1              1          10062.80      0  \n",
       "7                4            1              0         119346.88      1  \n",
       "8                2            0              1          74940.50      0  \n",
       "9                1            1              1          71725.73      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"whitegrid\")\n",
    "\n",
    "df = pd.read_csv(\"ChurnPrediction.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne *customer_id* est unique et ne sert pas dans la prédiction. Notons que nous avons à la fois des données numérique et catégorielle.\n",
    "\n",
    "**Consigne** : Supprimer la colonne *customer_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : En utilisant la méthode [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html), identifier s'il y a des valeurs qui paraissent aberrante dans les données numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Que peut-on dire des colonnes *tenure*, *products_number*, *credit_card* et *active_member* ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Calculer la proportion de déséquilibre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : En utilisant la fonction `agregate_column`, explorer les champs catégoriels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregate_column(column):\n",
    "    grouped = df.groupby(by=column, as_index=False).agg('mean')\n",
    "    return grouped[[column, \"churn\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "Maintenant que l'on a *un peu* observé les données, il nous reste à les préparer pour l'entraînement.\n",
    "\n",
    "**Consigne** : Séparer le dataset en *X* et *y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque *X* est composé de donnée numérique comme catégorielle et que l'implémentation scikit-learn ne peut pas prendre en compte les données catégorielles, il faut les convertir.\n",
    "\n",
    "**Consigne** : en utilisant la méthode [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html), convertir avec la méthode One-Hot-Encoding les données catégorielles en données numérique. On aura prit soin de capitaliser sur les observations précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation : Arbre\n",
    "\n",
    "On souhaite prédire le churn a partir des données que l'on vient de préparer à l'aide d'un arbre de décision. Nous allons réaliser une validation croisée pour avoir une meilleure vision des performances de l'algorithme.\n",
    "Cependant, le dataset est déséquilibré, donc nous ne pouvons pas réaliser une validation croisée sans prendre en compte ce déséquilibre.\n",
    "\n",
    "**Consigne** : Avant de régler ce problème, Construire une fonction `cross_validation_performance` qui prend en paramètre un vecteur *vector* et qui affiche la moyenne et l'écart-type au format suivant : *moyenne (+/- ecart-type)*. On veillera à transformer le vecteur au format *numpy* avant les traitements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_performance(vector):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Compléter le code suivant. Il utilise la méthode [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) pour entraîner un [arbre de décision](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn-tree-decisiontreeclassifier). Puis afficher les performances avec la fonction `cross_validation_performance`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne souhaite plus avoir ce bloc de code systématique, nous allons donc en faire une fonction. Pour pouvoir tester plusieurs paramétrage de l'arbre, on doit être capable de lui fournir des paramètres. Voici un exemple de l'utilisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cv = 5\n",
    "folds = StratifiedKFold(n_splits=cv).split(X, y)\n",
    "performances = []\n",
    "\n",
    "for (train_index, test_index) in folds:\n",
    "    X_train, X_test = ..., ...\n",
    "    y_train, y_test = ..., ...\n",
    "    \n",
    "    model_trained = DecisionTreeClassifier().fit(..., ...)\n",
    "    y_pred = model_trained.predict(...)\n",
    "    ...\n",
    "\n",
    "cross_validation_performance(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 8,\n",
    "    \"min_samples_leaf\": 20\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier(**parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : En exploitant ce fonctionnement, construire une fonction `stratified_cross_validation` qui prends en paramètre :\n",
    "* *X*: le dataset des features\n",
    "* *y*: le vecteur réponse\n",
    "* *model*: le modèle que l'on veut tester, au format scikit-learn\n",
    "* *parameters*: le dictionnaire de paramètres à transmettre à *model*\n",
    "* *metric*: la métrique avec laquelle on mesure les performances de *model*, au format scikit-learn\n",
    "* *cv*: le nombre de pli de la validation croisée\n",
    "\n",
    "Elle devra renvoyer les performances sur chacun des plis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_cross_validation(X, y, model, parameters, metric=f1_score, cv=3):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact de la profondeur\n",
    "\n",
    "On souhaiterai mesurer l'importance de la profondeur d'un arbre pour ce problème.\n",
    "\n",
    "**Consigne** : A l'aide de la fonction précédente, répondre à la problématique avec un affichage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette performance correspond en réalité au seuil 0.5. On souhaiterai être capable de trouver un seuil qui maximise le f1-score. \n",
    "\n",
    "## Trouver le seuil qui maximise une métrique\n",
    "\n",
    "Pour le faire, nous allons avoir besoin de trois bases :\n",
    "* Une base d'entraînement (*X_train*, *y_train*) : **entraîner** le modèle\n",
    "* Une base de validation (*X_valid*, *y_valid*) : **trouver** le meilleur seuil\n",
    "* Une base de test (*X_test*, *y_test*) : **tester** la performance sur des données non vues\n",
    "\n",
    "**Consigne** : Générer les trois bases à l'aide la fonction [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split), en prenant soin de conserver le même déséquilibre sur les trois bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Entraîner un arbre puis prédire les probabilités d'être de la classe d'intérêt pour le dataset de validation. Les stocker dans une variable *y_proba*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Construire une fonction `find_best_treshold` qui prends en paramètre :\n",
    "* *y_true* : vecteur des classes attendues\n",
    "* *y_proba* : vecteur de probabilité estimé des classes\n",
    "* *metric* : métrique à optimiser, au format scikit-learn\n",
    "Elle revoit la meilleure performance et le meilleur seuil pour la métrique sélectionnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_proba, metric):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Utiliser la fonction `find_best_threshold` sur le jeu de validation, et comparer avec la performance obtenue sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Reprendre la fonction `stratified_cross_validation` et la modifier pour afficher la meilleure performance que l'on puisse obtenir, avec en plus la valeur du seuil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_cross_validation(X, y, model, parameters, metric=f1_score, cv=3):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact de la profondeur : le retour\n",
    "\n",
    "Maintenant que l'on sait obtenir la meilleur version de chaque algorithme, on souhaite mesurer un peu mieux l'impact de la profondeur.\n",
    "\n",
    "**Consigne** : A l'aide de la fonction précédente, répondre à la problématique avec un affichage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaiterai avoir une représentation visuelle de cet affichage. Pour ce faire, on définit la fonction suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(parameters, performances, color=None, label=None,confidence=3):\n",
    "    if color is None: color=sns.color_palette()[0]\n",
    "    if label is None: label=\"\"\n",
    "        \n",
    "    mean = [performance.mean() for performance in performances]\n",
    "    deviation = [performance.std() for performance in performances]\n",
    "    \n",
    "    mean, deviation = np.array(mean), np.array(deviation)\n",
    "    \n",
    "    plt.fill_between(parameters, mean - confidence*deviation, mean + confidence*deviation, alpha=0.15, color=color)\n",
    "    plt.plot(parameters, mean, 'o-', color=color, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : en reprenant la question précédente (en adaptant), et en utilisant la fonction `plot_performance`, montrer visuellement l'impact de la profondeur sur la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Et la Random Forest ?\n",
    "\n",
    "On s'intéresse maintenant à la Random Forest. On souhaite mesurer la même chose que pour l'arbre.\n",
    "\n",
    "**Consigne** : reproduire la même étude, mais avec une Random Forest de 50 arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne** : Afficher sur le même graphique, avec une légende, les performances pour un arbre et pour une Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Et maintenant ?\n",
    "\n",
    "Il existe d'autres hyperparamètres important dans ces modèles. Reproduire les études, et comparer les performances entre arbres et Random Forest voire Extra-Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
